{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Command Line Interface\n",
    "\n",
    "Whether you run your commands directly in the terminal or through Python, it is a two-step process where you scrape the data into a JSON file and then convert the data to be useable in Python.  \n",
    "This section will cover scraping with the CLI commands, then using Pandas to read the JSON file.  \n",
    "Using command prompt, terminal, etc.  \n",
    "Scraping a specific Twitter user’s tweets:  \n",
    "In the example below, we’re scraping 100 tweets from Twitter user @jack. The code is entered in a command prompt/terminal. The code uses several optional arguments explained below.  \n",
    "--jsonl Outputs the data in a JSON format allowing you to access tweet information. Otherwise, you’ll only receive direct links to the tweets.  \n",
    "--progress Allows us to get updates from the CLI letting us know the progress of the scraping. It updates every 100 tweets. Does not appear to work when using Python with CLI.  \n",
    "--max-results # Puts a cap on the number of tweets scraped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from command prompt\n",
    "snscrape --jsonl --progress --max-results 100 twitter-search \"from:jack\" > user-tweets.json\n",
    "\n",
    "snscrape --jsonl --progress --max-results 500 --since 2020-06-01 twitter-search \"its the elephant until:2020-07-31\" > text-query-tweets.json\n",
    "\n",
    "snscrape --jsonl --progress --max-results 500 twitter-search \"its the elephant since:2020-06-01 until:2020-07-31\" > text-query-tweets.json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping a specific twitter user’s tweets:\n",
    "import os\n",
    "\n",
    "# Using OS library to call CLI commands in Python\n",
    "os.system(\"snscrape --jsonl --max-results 100 twitter-search 'from:jack'> user-tweets.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping historical tweets from a text search query:\n",
    "import os\n",
    "\n",
    "# Using OS library to call CLI commands in Python\n",
    "os.system(\"snscrape --jsonl --max-results 500 --since 2020-06-01 twitter-search 'its the elephant until:2020-07-31' > text-query-tweets.json\")\n",
    "\n",
    "#OR\n",
    "import os\n",
    "\n",
    "# Using OS library to call CLI commands in Python\n",
    "os.system(\"snscrape --jsonl --max-results 500 --since 2020-06-01 twitter-search \\\"its the elephant until:2020-07-31\\\" > text-query-tweets.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting JSON files to be usable in Python\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Reads the json generated from the CLI commands above and creates a pandas dataframe\n",
    "tweets_df = pd.read_json('text-query-tweets.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas\n",
    "\n",
    "# Creating list to append tweet data to\n",
    "tweets_list1 = []\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:jack').get_items()):\n",
    "    if i>100:\n",
    "        break\n",
    "    tweets_list1.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "    \n",
    "# Creating a dataframe from the tweets list above \n",
    "tweets_df1 = pd.DataFrame(tweets_list1, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas\n",
    "\n",
    "# Creating list to append tweet data to\n",
    "tweets_list2 = []\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('its the elephant since:2020-06-01 until:2020-07-31').get_items()):\n",
    "    if i>500:\n",
    "        break\n",
    "    tweets_list2.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "    \n",
    "# Creating a dataframe from the tweets list above\n",
    "tweets_df2 = pd.DataFrame(tweets_list2, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
